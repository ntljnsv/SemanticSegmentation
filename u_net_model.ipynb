{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-ondmBCbIM3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfC4GRwTrCEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b94194-b48c-446d-e9db-15d82f8a5d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKjtWerQYwTI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('drive/MyDrive/dpns/coco-stuff/meta.json', 'r') as f:\n",
        "    meta_data = json.load(f)\n",
        "\n",
        "class_id_to_index = {cls['id']: idx for idx, cls in enumerate(meta_data['classes'])}\n",
        "class_title_to_index = {cls['title']: idx for idx, cls in enumerate(meta_data['classes'])}\n",
        "n_classes = len(meta_data['classes'])\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isnWpP3PJFJn"
      },
      "outputs": [],
      "source": [
        "dataset = 'drive/MyDrive/dpns/coco-stuff'\n",
        "\n",
        "train_dir = f'{dataset}/train'\n",
        "train_img_dir = f'{train_dir}/img'\n",
        "train_ann_dir= f'{train_dir}/ann'\n",
        "\n",
        "val_dir = f'{dataset}/test'\n",
        "val_img_dir = f'{val_dir}/img'\n",
        "val_ann_dir = f'{val_dir}/ann'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oj4jRK-anq0"
      },
      "outputs": [],
      "source": [
        "def load_image(img_path, size=(224, 224)):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, size)\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQoEgtkCbONW"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import zlib\n",
        "\n",
        "def bitmap_to_mask(bitmap_data, origin, height, width):\n",
        "    compressed_data = base64.b64decode(bitmap_data)\n",
        "    decompressed_data = zlib.decompress(compressed_data)\n",
        "\n",
        "    n = np.frombuffer(decompressed_data, np.uint8)\n",
        "    imdecoded = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    mask = imdecoded[:, :, 3].astype(bool)\n",
        "\n",
        "    full_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "    x, y = origin\n",
        "    full_mask[y:y + mask.shape[0], x:x + mask.shape[1]] = mask\n",
        "    return full_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clyLTIAAJGd7"
      },
      "outputs": [],
      "source": [
        "def load_mask(ann_path, size=(224, 224), n_classes=n_classes):\n",
        "    with open(ann_path, 'r') as file:\n",
        "        annotation = json.load(file)\n",
        "\n",
        "    height = annotation['size']['height']\n",
        "    width = annotation['size']['width']\n",
        "    mask = np.zeros((height, width), dtype=np.int32)\n",
        "    for obj in annotation['objects']:\n",
        "        class_id = obj['classId']\n",
        "        class_index = class_id_to_index[class_id]\n",
        "        bitmap_data = obj['bitmap']['data']\n",
        "        origin = obj['bitmap']['origin']\n",
        "\n",
        "        obj_mask = bitmap_to_mask(bitmap_data, origin, height, width)\n",
        "        mask = np.maximum(mask, obj_mask * class_index)\n",
        "\n",
        "    mask = cv2.resize(mask, size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    mask_one_hot = np.zeros((*size, n_classes), dtype=np.float32)\n",
        "    for c in range(n_classes):\n",
        "        mask_one_hot[:, :, c] = (mask == c).astype(float)\n",
        "    return mask_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti5oJT8IMhuk"
      },
      "outputs": [],
      "source": [
        "def data_augment(image, mask):\n",
        "    flip_left_right = tf.random.uniform([], 0, 1) > 0.5\n",
        "    flip_up_down = tf.random.uniform([], 0, 1) > 0.5\n",
        "\n",
        "    if flip_left_right:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        mask = tf.image.flip_left_right(mask)\n",
        "\n",
        "    if flip_up_down:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "        mask = tf.image.flip_up_down(mask)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    image = tf.image.random_hue(image, max_delta=0.1)\n",
        "    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnLilv7AHkwK"
      },
      "outputs": [],
      "source": [
        "def load_paths(img_dir, ann_dir):\n",
        "    img_paths = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir)])\n",
        "    ann_paths = sorted([os.path.join(ann_dir, f) for f in os.listdir(ann_dir)])\n",
        "\n",
        "    return img_paths, ann_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUp6WH0-cOCd"
      },
      "outputs": [],
      "source": [
        "def train_data_generator(img_paths, ann_paths, batch_size=batch_size, size=(224, 224), n_classes=n_classes):\n",
        "    indices = np.arange(len(img_paths))\n",
        "    np.random.shuffle(indices)\n",
        "    img_paths = np.array(img_paths)[indices]\n",
        "    ann_paths = np.array(ann_paths)[indices]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, ann_paths))\n",
        "    def load_data(img_path, ann_path):\n",
        "        img = load_image(img_path, size)\n",
        "        mask = tf.numpy_function(load_mask, inp=[ann_path, size, n_classes], Tout=tf.float32)\n",
        "        img.set_shape((size[0], size[1], 3))\n",
        "        mask.set_shape((size[0], size[1], n_classes))\n",
        "        img, mask = data_augment(img, mask)\n",
        "        return img, mask\n",
        "\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kphgwc74bLK"
      },
      "outputs": [],
      "source": [
        "def val_data_generator(img_paths, ann_paths, batch_size=batch_size, size=(224, 224), n_classes=n_classes):\n",
        "    indices = np.arange(len(img_paths))\n",
        "    np.random.shuffle(indices)\n",
        "    img_paths = np.array(img_paths)[indices]\n",
        "    ann_paths = np.array(ann_paths)[indices]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, ann_paths))\n",
        "    def load_data(img_path, ann_path):\n",
        "        img = load_image(img_path, size)\n",
        "        mask = tf.numpy_function(load_mask, inp=[ann_path, size, n_classes], Tout=tf.float32)\n",
        "        img.set_shape((size[0], size[1], 3))\n",
        "        mask.set_shape((size[0], size[1], n_classes))\n",
        "        return img, mask\n",
        "\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY6ji2arx1E7"
      },
      "outputs": [],
      "source": [
        "train_img_paths, train_ann_paths = load_paths(train_img_dir, train_ann_dir)\n",
        "train_gen = train_data_generator(train_img_paths, train_ann_paths, batch_size=batch_size, size=(224, 224), n_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsqoSHmOx1i8"
      },
      "outputs": [],
      "source": [
        "val_img_paths, val_ann_paths = load_paths(val_img_dir, val_ann_dir)\n",
        "val_gen = val_data_generator(val_img_paths, val_ann_paths, batch_size=batch_size, size=(224, 224), n_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-VSPKjCTEtn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "def build_model(n_classes=n_classes, IMG_HEIGHT=224, IMG_WIDTH=224, IMG_CHANNELS=3):\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name=\"input_image\")\n",
        "\n",
        "    encoder = MobileNetV2(input_tensor=inputs, include_top=False)\n",
        "\n",
        "    BASE_WEIGHT_PATH = ('https://github.com/fchollet/deep-learning-models/releases/download/v0.6/')\n",
        "    model_name = 'mobilenet_%s_%d_tf_no_top.h5' % ('1_0', 224)\n",
        "    weight_path = BASE_WEIGHT_PATH + model_name\n",
        "    weights_path = keras.utils.get_file(model_name, weight_path)\n",
        "    encoder.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "\n",
        "    skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\n",
        "    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n",
        "\n",
        "    x = encoder_output\n",
        "    skip_1 = encoder.get_layer(skip_connection_names[-1]).output\n",
        "    skip_2 = encoder.get_layer(skip_connection_names[-2]).output\n",
        "    skip_3 = encoder.get_layer(skip_connection_names[-3]).output\n",
        "    skip_4 = encoder.get_layer(skip_connection_names[-4]).output\n",
        "\n",
        "    u6 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    u6 = concatenate([u6, skip_1])\n",
        "    c6 = Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Activation('relu')(c6)\n",
        "    c6 = Dropout(0.3)(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, skip_2])\n",
        "    c7 = Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Activation('relu')(c7)\n",
        "    c7 = Dropout(0.3)(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, skip_3])\n",
        "    c8 = Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Activation('relu')(c8)\n",
        "    c8 = Dropout(0.2)(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, skip_4])\n",
        "    c9 = Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Activation('relu')(c9)\n",
        "    c9 = Dropout(0.2)(c9)\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RcsWPib5erj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import  mixed_precision\n",
        "\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V4htUvk5ZY6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbxfmxWxLieU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='drive/MyDrive/dpns/model_checkpoint_v5.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf87Yy2OV1Ti"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    min_lr=1e-8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WyvamdG77FRQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = build_model(n_classes=n_classes)\n",
        "\n",
        "encoder_layers = model.layers[0:-22]\n",
        "\n",
        "for layer in encoder_layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BfCcvLkAKjX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "optimizer = Adam(learning_rate=initial_learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcTMhzpLDTxs"
      },
      "outputs": [],
      "source": [
        "def dice_loss(y_true, y_pred, smooth=1e-4):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f)\n",
        "\n",
        "    return 1 - (2. * intersection + smooth) / (union + smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmgrWH6acMjV"
      },
      "outputs": [],
      "source": [
        "def combo_loss(y_true, y_pred):\n",
        "     return tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A6Aa7GtKJm8z"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer, loss=combo_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7Sr4wzAvXqn"
      },
      "outputs": [],
      "source": [
        "model.fit(train_gen,\n",
        "          steps_per_epoch=len(os.listdir(train_img_dir)) // batch_size,\n",
        "          validation_steps=len(os.listdir(val_img_dir)) // batch_size,\n",
        "          epochs=20,\n",
        "          validation_data=val_gen,\n",
        "          callbacks=[early_stopping, checkpoint, reduce_lr])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}